# Nori Analyzer를 활용해 한글(korean)이 제대로 검색되게 만들기
## ✅ Nori Analyzer를 활용해 한글(korean)이 제대로 검색되게 만들기

1. Nori Analyzer를 사용하려면 플러그인을 설치해야 한다. 플러그인을 설치한 채로 Docker 컨테이너를 다시 띄우기 위해서 기존에 실행하던 컨테이너를 종료 한다.
```shell
# 실행되고 있는 컨테이너 확인
docker ps

# compose.yml 파일이 있는 경로에서 아래 명령어 실행
docker compose down

# 종료 확인
docker ps
```

2. Dockerfile 파일, compose.yml 작성
* Dockerfile
```dockerfile
From docker.elastic.co/elasticsearch/elasticsearch:8.17.4

# Nori Analyzer 플러그인 설치
RUN bin/elasticsearch-plugin install analysis-nori
```
* compose.yml
```yaml
services:
    elastic:
        build:
          context: .
          dockerfile: Dockerfile
        ports:
          - 9200:9200
        environment:
          - discovery.type=single-node 
          - xpack.security.enabled=false
          - xpack.security.http.ssl.enabled=false
    kibana:
        image: docker.elastic.co/kibana/kibana:8.17.4
        ports:
          - 5601:5601
        environment:
          - ELASTICSEARCH_HOSTS=http://elastic:9200
```

3. 컨테이너 띄우기
```shell
docker compose up -d
```

4. nori-analyzer 적용
```
// 인덱스 생성 + 매핑 정의 + Custom Analyzer 적용
PUT /boards
{
    "settings": {
        "analysis": {
            "analyzer": {
                "boards_content_analyzer": {
                    "char_filter": [],
                    "tokenizer": "nori_tokenizer",
                    "filter": ["nori_part_of_speech", "lowercase", "nori_readingform"]
                }
            }
        }
    },
    "mappings": {
        "properties": {
            "content": {
                "type": "text",
                "analyzer": "boards_content_analyzer"
            }
        }
    }
}

GET /boards

POST /boards/_doc
{
    "content": "백화점에서 쇼핑을 하다가 친구를 만났다."
}

GET /boards/_search
{
    "query": {
        "match": {
          "content": "쇼핑"
        }
    }
}

GET /boards/_analyze
{
    "field": "content",
    "text": "백화점에서 쇼핑을 하다가 친구를 만났다."
}


GET /_analyze
{
    "text": "백화점에서 쇼핑을 하다가 친구를 만났다.",
    "analyzer": "nori"
}

GET /_analyze
{
    "text": "백화점에서 쇼핑을 하다가 친구를 만났다.",
    "char_filter": [],
    "tokenizer": "nori_tokenizer",
    "filter": ["nori_part_of_speech", "lowercase", "nori_readingform"]
}
```